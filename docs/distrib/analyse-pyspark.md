# Analyse de données avec PySpark

Réaliser une études sur un dataset fourni par [kaggle](https://www.kaggle.com/datasets) en utilisant pyspark.

- Implémenter les opérations de base de pyspark SQL (1 poinnt pour chaque)
    - filtrage 
    - sélection de colonnes
    - agrégation
    - Création d'une nouvelle colonne à partir de colonnes existantes
- Dessiner un graphique (1 point pour chaque)
    - Histogramme
    - Nuage de points
    - Boîte à moustaches
- Illustrer votre compréhension de l'aspect distribué de pyspark (1 point pour chaque)
    - Mettre en place un master et deux workers en local
    - Définir deux applications pyspark et les lancer en parallèle sur le cluster local
    - Montrer la répartition des données sur les workers
    - Montrer les plans d'exécution
- Lancer le projet sur Databricks (3 points)
- Présenter les graphiques et quelques résultats sur une interface streamlit (3 points)
- Votre auto évaluation est demandée (à soumettre au moment de l'évaluation)
- La note sera normalisée sur 20 points.